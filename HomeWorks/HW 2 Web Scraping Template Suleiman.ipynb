{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Social Network Data Analysis</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Home Assignment #2: Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <hr /> General Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due Date:** 08.12.2020 18:30 <br>\n",
    "**Late submission policy:** -1 points per day <br>\n",
    "\n",
    "\n",
    "Please send completed assignments to iakarpov@hse.ru with the following subject:\n",
    "**HSE SNA UD 2020 {LastName} {First Name} HW_2\n",
    "\n",
    "Complete your code with pictures and explanations.\n",
    "If you are using IPython Notebook, you can use this file as a template for your homework.\n",
    "\n",
    "In this homework assignment, you are invited to implement a parsing tool to get data from an arbitrary social network: vkontakte, twitter (suggest yourself). You can collect posts, friends, subscribers or groups of a user or group members\n",
    "Base score (code works without you and retrieves data) - 8.\n",
    "Additional points can be received for processing complex cases (authorization implementation, asynchronous processing, solving the ban problem during a mass collection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Resource analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1. In case of researchgate you are supposed to extract information about researchers that are occupied in the area of social network analysis you can be done by scraping posts that Are related to several tags for example https://www.researchgate.net/topic/Social-Network-Analysis.\n",
    "Your first task is to get all researchers that post messages in https://www.researchgate.net/topic/Social-Network-Analysis, Then collect their research activities and their Following and Followers. To do it first of all inspect if researchgate has a public or private API and can you use it. <br>\n",
    "1.2. Open the necessary page and browser load the content as HTML page save it to your jupyter homework notebook . <br>\n",
    "1.3. Get necessary constant using beautifulsoup and Document object model  (DOM) <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Crawling implementation\n",
    "2.1. Find request that your actions necessary data using private or public appearance and export it as cUrl . Show this request in Postman and remove unnecessary headers. Show That's the request is working without them. <br>\n",
    "2.2. If you need to eat straight through several parameters like page number or post number, Show how to iterate through them. <br>\n",
    "2.3. Transfer your Postman request to python using “code export” option <br>\n",
    "2.4. Implement your crawler as stand-alone project/program with __main__ function and parameters <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Saving results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. Run mongodb as a docker container or use the DB at 37.228.117.120:27017. <br>\n",
    "An example of creating a docker container is shown below: <br>\n",
    "\n",
    "* container name - some_mongo\n",
    "* user - user\n",
    "* password P@ssw0rdHSE\n",
    "* image name - mongo\n",
    "* external port through which the base will be available - 27017\n",
    "* port inside the container - 27017 (second number) <br>\n",
    "\n",
    "``` bash\n",
    "docker run --name some_mongo -p 27017: 27017 -d -v mongo_volume: / data / db -e MONGO_INITDB_ROOT_USERNAME = user -e MONGO_INITDB_ROOT_PASSWORD = P @ ssw0rdHSE mongo\n",
    "```\n",
    "\n",
    "3.2. Implement saving results in DBMS <br>\n",
    "An example of an entry in the DBMS at 37.228.117.120:27017 is shown below: <br>\n",
    "* user - user\n",
    "* password - P%40ssw0rdHSE\n",
    "* ip address - 37.228.117.120\n",
    "* port - 27017\n",
    "* database name - kek_db\n",
    "* table name - kek_col <br>\n",
    "\n",
    "``` python\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "#create dataframe sfrom csv\n",
    "df = pd.read_csv('stockerbot-export1.csv')\n",
    "#convert all data to records dict\n",
    "data = df.to_dict('records')\n",
    "#init mongodb client\n",
    "client = MongoClient(\"mongodb://user:P%40ssw0rdHSE@37.228.117.120:27017\")[\"kek_db\"] [\"kek_col\"]\n",
    "#insert data to mongodb\n",
    "client.insert_many(data)\n",
    "```\n",
    "\n",
    "3.3. Implement reading and displaying results from a DBMS <br>\n",
    "example of reading from database <br>\n",
    "\n",
    "``` python\n",
    "client.find({})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. Analyze possible data collection problems\n",
    "4.1. check query limits / if you get banned after a while <br>\n",
    "4.2. implement token fetch / user authorization <br>\n",
    "4.3. think over how to assign a global identifier to the collection elements that will not change from time to time - this is necessary in order to quickly check what data is already in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}